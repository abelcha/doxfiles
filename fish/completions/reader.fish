# Fish completion for reader
complete -c reader -f
complete -c reader -f -n "__fish_use_subcommand" -a read_csv -d "Read data using read_csv"
complete -c reader -f -n "__fish_use_subcommand" -a read_json -d "Read data using read_json"
complete -c reader -f -n "__fish_use_subcommand" -a read_ndjson -d "Read data using read_ndjson"
complete -c reader -f -n "__fish_use_subcommand" -a read_parquet -d "Read data using read_parquet"
complete -c reader -f -n "__fish_use_subcommand" -a read_xlsx -d "Read data using read_xlsx"
complete -c reader -f -n "__fish_use_subcommand" -a fish_completion -d "Generate Fish shell completion script"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l all-varchar -d "Skip type detection and assume all columns are of type VARCHAR"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l allow-quoted-nulls -d "Allow the conversion of quoted values to NULL values"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l auto-detect -d "Auto detect CSV parameters"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l auto-type-candidates -d "Types that the sniffer uses when detecting column types"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l buffer-size -d "Size of the buffers used to read files, in bytes"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l column-names -d "Alias for names"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l column-types -d "Alias for types"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l columns -d "Column names and types, as a struct"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l comment -d "Character used to initiate comments"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Method used to compress CSV files"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l dateformat -d "Date format used when parsing and writing dates"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l decimal-separator -d "Decimal separator for numbers"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l delim -d "Delimiter character used to separate columns"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l dtypes -d "Alias for types"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l encoding -a "utf-8 utf-16 latin-1" -d "Encoding used by the CSV file"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l escape -d "String used to escape the quote character within quoted values"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l filename -d "Add path of the containing file to each row to a column named 'filename'"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l files-to-sniff -d "Number of lines at the top of the file to scan for auto-detection"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l force-not-null -d "Do not match values in the specified columns against the NULL string"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l header -d "First line of each file contains the column names"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l hive-partitioning -d "Interpret the path as a Hive partitioned path"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l hive-types -d "Hive types"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l hive-types-autocast -d "Hive types autocast"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l ignore-errors -d "Ignore any parsing errors encountered"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l max-line-size -d "Maximum line size, in bytes"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l maximum-line-size -d "Alias for max_line_size"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l names -d "Column names, as a list"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l new-line -a "\r \n \r\n" -d "New line character(s)"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l normalize-names -d "Normalize column names"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l null-padding -d "Pad the remaining columns on the right with NULL values when a line lacks columns"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l nullstr -d "Strings that represent a NULL value"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l parallel -d "Use the parallel CSV reader"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l quote -d "String used to quote values"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l rejects-limit -d "Upper limit on the number of faulty lines per file that are recorded"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l rejects-scan -d "Name of the temporary table where information on faulty scans is stored"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l rejects-table -d "Name of the temporary table where information on faulty lines is stored"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l sample-size -d "Number of sample lines for auto detection"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l sep -d "Delimiter character used to separate columns"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l skip -d "Number of lines to skip at the start of each file"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l store-rejects -d "Skip any lines with errors and store them in the rejects table"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l strict-mode -d "Enforces the strictness level of the CSV Reader"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l thousands -d "The thousands separator"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l timestampformat -d "Timestamp format used when parsing and writing timestamps"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l types -d "Column types, as either a list (by position) or a struct (by name)"
complete -c reader -f -n "__fish_seen_subcommand_from read_csv" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "__fish_seen_subcommand_from read_json" -l auto-detect -d "Whether to auto-detect the names of the keys and data types"
complete -c reader -f -n "__fish_seen_subcommand_from read_json" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Compression method (gzip, zstd, etc"
complete -c reader -f -n "__fish_seen_subcommand_from read_json" -l convert-strings-to-integers -d "Convert strings to integers"
complete -c reader -f -n "__fish_seen_subcommand_from read_json" -l format -a "auto newline_delimited array parquet csv tsv json jsonl arrow" -d "JSON format ('auto', 'newline_delimited', 'array')"
complete -c reader -f -n "__fish_seen_subcommand_from read_json" -l ignore-errors -d "Ignore parse errors"
complete -c reader -f -n "__fish_seen_subcommand_from read_json" -l maximum-object-size -d "Maximum object size in bytes"
complete -c reader -f -n "__fish_seen_subcommand_from read_json" -l sample-size -d "Number of sample objects for detection"
complete -c reader -f -n "__fish_seen_subcommand_from read_json" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "__fish_seen_subcommand_from read_ndjson" -l auto-detect -d "Whether to auto-detect the names of the keys and data types"
complete -c reader -f -n "__fish_seen_subcommand_from read_ndjson" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Compression method (gzip, zstd, etc"
complete -c reader -f -n "__fish_seen_subcommand_from read_ndjson" -l convert-strings-to-integers -d "Convert strings to integers"
complete -c reader -f -n "__fish_seen_subcommand_from read_ndjson" -l format -a "auto newline_delimited array parquet csv tsv json jsonl arrow" -d "JSON format ('auto', 'newline_delimited', 'array')"
complete -c reader -f -n "__fish_seen_subcommand_from read_ndjson" -l ignore-errors -d "Ignore parse errors"
complete -c reader -f -n "__fish_seen_subcommand_from read_ndjson" -l maximum-object-size -d "Maximum object size in bytes"
complete -c reader -f -n "__fish_seen_subcommand_from read_ndjson" -l sample-size -d "Number of sample objects for detection"
complete -c reader -f -n "__fish_seen_subcommand_from read_ndjson" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "__fish_seen_subcommand_from read_parquet" -l binary-as-string -d "Load binary columns as strings"
complete -c reader -f -n "__fish_seen_subcommand_from read_parquet" -l can-have-nan -d "Whether or not to include the can_have_nan column"
complete -c reader -f -n "__fish_seen_subcommand_from read_parquet" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Compression method (snappy, zstd, etc"
complete -c reader -f -n "__fish_seen_subcommand_from read_parquet" -l filename -d "Include filename column"
complete -c reader -f -n "__fish_seen_subcommand_from read_parquet" -l hive-partitioning -d "Interpret path as Hive partitioned path"
complete -c reader -f -n "__fish_seen_subcommand_from read_parquet" -l union-by-name -d "Union multiple schemas by name"
complete -c reader -f -n "__fish_seen_subcommand_from read_xlsx" -l header -d "Treat first row as column names"
complete -c reader -f -n "__fish_seen_subcommand_from read_xlsx" -l sheet -d "Name of the sheet to read"
complete -c reader -f -n "__fish_seen_subcommand_from read_xlsx" -l all-varchar -d "Read all cells as VARCHARs"
complete -c reader -f -n "__fish_seen_subcommand_from read_xlsx" -l range -d "Range of cells to read (e"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l all-varchar -d "Skip type detection and assume all columns are of type VARCHAR"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l allow-quoted-nulls -d "Allow the conversion of quoted values to NULL values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l auto-detect -d "Auto detect CSV parameters"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l auto-type-candidates -d "Types that the sniffer uses when detecting column types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l buffer-size -d "Size of the buffers used to read files, in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l column-names -d "Alias for names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l column-types -d "Alias for types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l columns -d "Column names and types, as a struct"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l comment -d "Character used to initiate comments"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Method used to compress CSV files"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l dateformat -d "Date format used when parsing and writing dates"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l decimal-separator -d "Decimal separator for numbers"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l delim -d "Delimiter character used to separate columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l dtypes -d "Alias for types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l encoding -a "utf-8 utf-16 latin-1" -d "Encoding used by the CSV file"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l escape -d "String used to escape the quote character within quoted values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l filename -d "Add path of the containing file to each row to a column named 'filename'"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l files-to-sniff -d "Number of lines at the top of the file to scan for auto-detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l force-not-null -d "Do not match values in the specified columns against the NULL string"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l header -d "First line of each file contains the column names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l hive-partitioning -d "Interpret the path as a Hive partitioned path"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l hive-types -d "Hive types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l hive-types-autocast -d "Hive types autocast"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l ignore-errors -d "Ignore any parsing errors encountered"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l max-line-size -d "Maximum line size, in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l maximum-line-size -d "Alias for max_line_size"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l names -d "Column names, as a list"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l new-line -a "\r \n \r\n" -d "New line character(s)"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l normalize-names -d "Normalize column names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l null-padding -d "Pad the remaining columns on the right with NULL values when a line lacks columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l nullstr -d "Strings that represent a NULL value"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l parallel -d "Use the parallel CSV reader"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l quote -d "String used to quote values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l rejects-limit -d "Upper limit on the number of faulty lines per file that are recorded"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l rejects-scan -d "Name of the temporary table where information on faulty scans is stored"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l rejects-table -d "Name of the temporary table where information on faulty lines is stored"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l sample-size -d "Number of sample lines for auto detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l sep -d "Delimiter character used to separate columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l skip -d "Number of lines to skip at the start of each file"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l store-rejects -d "Skip any lines with errors and store them in the rejects table"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l strict-mode -d "Enforces the strictness level of the CSV Reader"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l thousands -d "The thousands separator"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l timestampformat -d "Timestamp format used when parsing and writing timestamps"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l types -d "Column types, as either a list (by position) or a struct (by name)"
complete -c reader -f -n "commandline -opc | string match -rg '\\.csv\$'" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l all-varchar -d "Skip type detection and assume all columns are of type VARCHAR"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l allow-quoted-nulls -d "Allow the conversion of quoted values to NULL values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l auto-detect -d "Auto detect CSV parameters"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l auto-type-candidates -d "Types that the sniffer uses when detecting column types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l buffer-size -d "Size of the buffers used to read files, in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l column-names -d "Alias for names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l column-types -d "Alias for types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l columns -d "Column names and types, as a struct"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l comment -d "Character used to initiate comments"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Method used to compress CSV files"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l dateformat -d "Date format used when parsing and writing dates"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l decimal-separator -d "Decimal separator for numbers"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l delim -d "Delimiter character used to separate columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l dtypes -d "Alias for types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l encoding -a "utf-8 utf-16 latin-1" -d "Encoding used by the CSV file"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l escape -d "String used to escape the quote character within quoted values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l filename -d "Add path of the containing file to each row to a column named 'filename'"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l files-to-sniff -d "Number of lines at the top of the file to scan for auto-detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l force-not-null -d "Do not match values in the specified columns against the NULL string"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l header -d "First line of each file contains the column names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l hive-partitioning -d "Interpret the path as a Hive partitioned path"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l hive-types -d "Hive types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l hive-types-autocast -d "Hive types autocast"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l ignore-errors -d "Ignore any parsing errors encountered"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l max-line-size -d "Maximum line size, in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l maximum-line-size -d "Alias for max_line_size"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l names -d "Column names, as a list"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l new-line -a "\r \n \r\n" -d "New line character(s)"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l normalize-names -d "Normalize column names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l null-padding -d "Pad the remaining columns on the right with NULL values when a line lacks columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l nullstr -d "Strings that represent a NULL value"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l parallel -d "Use the parallel CSV reader"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l quote -d "String used to quote values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l rejects-limit -d "Upper limit on the number of faulty lines per file that are recorded"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l rejects-scan -d "Name of the temporary table where information on faulty scans is stored"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l rejects-table -d "Name of the temporary table where information on faulty lines is stored"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l sample-size -d "Number of sample lines for auto detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l sep -d "Delimiter character used to separate columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l skip -d "Number of lines to skip at the start of each file"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l store-rejects -d "Skip any lines with errors and store them in the rejects table"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l strict-mode -d "Enforces the strictness level of the CSV Reader"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l thousands -d "The thousands separator"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l timestampformat -d "Timestamp format used when parsing and writing timestamps"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l types -d "Column types, as either a list (by position) or a struct (by name)"
complete -c reader -f -n "commandline -opc | string match -rg '\\.txt\$'" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l all-varchar -d "Skip type detection and assume all columns are of type VARCHAR"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l allow-quoted-nulls -d "Allow the conversion of quoted values to NULL values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l auto-detect -d "Auto detect CSV parameters"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l auto-type-candidates -d "Types that the sniffer uses when detecting column types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l buffer-size -d "Size of the buffers used to read files, in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l column-names -d "Alias for names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l column-types -d "Alias for types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l columns -d "Column names and types, as a struct"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l comment -d "Character used to initiate comments"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Method used to compress CSV files"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l dateformat -d "Date format used when parsing and writing dates"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l decimal-separator -d "Decimal separator for numbers"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l delim -d "Delimiter character used to separate columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l dtypes -d "Alias for types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l encoding -a "utf-8 utf-16 latin-1" -d "Encoding used by the CSV file"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l escape -d "String used to escape the quote character within quoted values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l filename -d "Add path of the containing file to each row to a column named 'filename'"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l files-to-sniff -d "Number of lines at the top of the file to scan for auto-detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l force-not-null -d "Do not match values in the specified columns against the NULL string"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l header -d "First line of each file contains the column names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l hive-partitioning -d "Interpret the path as a Hive partitioned path"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l hive-types -d "Hive types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l hive-types-autocast -d "Hive types autocast"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l ignore-errors -d "Ignore any parsing errors encountered"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l max-line-size -d "Maximum line size, in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l maximum-line-size -d "Alias for max_line_size"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l names -d "Column names, as a list"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l new-line -a "\r \n \r\n" -d "New line character(s)"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l normalize-names -d "Normalize column names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l null-padding -d "Pad the remaining columns on the right with NULL values when a line lacks columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l nullstr -d "Strings that represent a NULL value"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l parallel -d "Use the parallel CSV reader"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l quote -d "String used to quote values"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l rejects-limit -d "Upper limit on the number of faulty lines per file that are recorded"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l rejects-scan -d "Name of the temporary table where information on faulty scans is stored"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l rejects-table -d "Name of the temporary table where information on faulty lines is stored"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l sample-size -d "Number of sample lines for auto detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l sep -d "Delimiter character used to separate columns"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l skip -d "Number of lines to skip at the start of each file"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l store-rejects -d "Skip any lines with errors and store them in the rejects table"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l strict-mode -d "Enforces the strictness level of the CSV Reader"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l thousands -d "The thousands separator"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l timestampformat -d "Timestamp format used when parsing and writing timestamps"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l types -d "Column types, as either a list (by position) or a struct (by name)"
complete -c reader -f -n "commandline -opc | string match -rg '\\.tsv\$'" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "commandline -opc | string match -rg '\\.json\$'" -l auto-detect -d "Whether to auto-detect the names of the keys and data types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.json\$'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Compression method (gzip, zstd, etc"
complete -c reader -f -n "commandline -opc | string match -rg '\\.json\$'" -l convert-strings-to-integers -d "Convert strings to integers"
complete -c reader -f -n "commandline -opc | string match -rg '\\.json\$'" -l format -a "auto newline_delimited array parquet csv tsv json jsonl arrow" -d "JSON format ('auto', 'newline_delimited', 'array')"
complete -c reader -f -n "commandline -opc | string match -rg '\\.json\$'" -l ignore-errors -d "Ignore parse errors"
complete -c reader -f -n "commandline -opc | string match -rg '\\.json\$'" -l maximum-object-size -d "Maximum object size in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.json\$'" -l sample-size -d "Number of sample objects for detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.json\$'" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "commandline -opc | string match -rg '\\.jsonl\$'" -l auto-detect -d "Whether to auto-detect the names of the keys and data types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.jsonl\$'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Compression method (gzip, zstd, etc"
complete -c reader -f -n "commandline -opc | string match -rg '\\.jsonl\$'" -l convert-strings-to-integers -d "Convert strings to integers"
complete -c reader -f -n "commandline -opc | string match -rg '\\.jsonl\$'" -l format -a "auto newline_delimited array parquet csv tsv json jsonl arrow" -d "JSON format ('auto', 'newline_delimited', 'array')"
complete -c reader -f -n "commandline -opc | string match -rg '\\.jsonl\$'" -l ignore-errors -d "Ignore parse errors"
complete -c reader -f -n "commandline -opc | string match -rg '\\.jsonl\$'" -l maximum-object-size -d "Maximum object size in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.jsonl\$'" -l sample-size -d "Number of sample objects for detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.jsonl\$'" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "commandline -opc | string match -rg '\\.ndjson\$'" -l auto-detect -d "Whether to auto-detect the names of the keys and data types"
complete -c reader -f -n "commandline -opc | string match -rg '\\.ndjson\$'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Compression method (gzip, zstd, etc"
complete -c reader -f -n "commandline -opc | string match -rg '\\.ndjson\$'" -l convert-strings-to-integers -d "Convert strings to integers"
complete -c reader -f -n "commandline -opc | string match -rg '\\.ndjson\$'" -l format -a "auto newline_delimited array parquet csv tsv json jsonl arrow" -d "JSON format ('auto', 'newline_delimited', 'array')"
complete -c reader -f -n "commandline -opc | string match -rg '\\.ndjson\$'" -l ignore-errors -d "Ignore parse errors"
complete -c reader -f -n "commandline -opc | string match -rg '\\.ndjson\$'" -l maximum-object-size -d "Maximum object size in bytes"
complete -c reader -f -n "commandline -opc | string match -rg '\\.ndjson\$'" -l sample-size -d "Number of sample objects for detection"
complete -c reader -f -n "commandline -opc | string match -rg '\\.ndjson\$'" -l union-by-name -d "Whether the columns of multiple files should be combined by name"
complete -c reader -f -n "commandline -opc | string match -rg '\\.parquet\$'" -l binary-as-string -d "Load binary columns as strings"
complete -c reader -f -n "commandline -opc | string match -rg '\\.parquet\$'" -l can-have-nan -d "Whether or not to include the can_have_nan column"
complete -c reader -f -n "commandline -opc | string match -rg '\\.parquet\$'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "Compression method (snappy, zstd, etc"
complete -c reader -f -n "commandline -opc | string match -rg '\\.parquet\$'" -l filename -d "Include filename column"
complete -c reader -f -n "commandline -opc | string match -rg '\\.parquet\$'" -l hive-partitioning -d "Interpret path as Hive partitioned path"
complete -c reader -f -n "commandline -opc | string match -rg '\\.parquet\$'" -l union-by-name -d "Union multiple schemas by name"
complete -c reader -f -n "commandline -opc | string match -rg '\\.xlsx\$'" -l header -d "Treat first row as column names"
complete -c reader -f -n "commandline -opc | string match -rg '\\.xlsx\$'" -l sheet -d "Name of the sheet to read"
complete -c reader -f -n "commandline -opc | string match -rg '\\.xlsx\$'" -l all-varchar -d "Read all cells as VARCHARs"
complete -c reader -f -n "commandline -opc | string match -rg '\\.xlsx\$'" -l range -d "Range of cells to read (e"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "COPY [csv] Compression type: auto, none, gzip, zstd, snappy, brotli, lz4"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.parquet)'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "COPY [parquet] Compression type: auto, none, gzip, zstd, snappy, brotli, lz4"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.json|\\.jsonl|\\.ndjson)'" -l compression -a "uncompressed brotli gzip snappy lz4 lz4_raw zstd auto none" -d "COPY [json] Compression type: auto, none, gzip, zstd, snappy, brotli, lz4"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l dateformat -d "COPY [csv] Date format for writing dates"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.json|\\.jsonl|\\.ndjson)'" -l dateformat -d "COPY [json] Date format for writing dates"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l delim -d "COPY [csv] Delimiter character to separate columns"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l sep -d "COPY [csv] Alias for delim"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l escape -d "COPY [csv] Character before a quote character within quoted values"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l force-quote -d "COPY [csv] List of columns to always add quotes to"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l header -d "COPY [csv] Whether to write a header for the CSV file"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l nullstr -d "COPY [csv] String to represent NULL value"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l prefix -d "COPY [csv] Prefix string for CSV file"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l suffix -d "COPY [csv] Suffix string for CSV file"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l quote -d "COPY [csv] Quoting character for data values"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.csv|\\.tsv|\\.txt)'" -l timestampformat -d "COPY [csv] Timestamp format for writing"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.json|\\.jsonl|\\.ndjson)'" -l timestampformat -d "COPY [json] Timestamp format for writing"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.parquet)'" -l compression-level -d "COPY [parquet] Compression level 1-22 (only for zstd)"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.parquet)'" -l field-ids -d "COPY [parquet] Field ID for each column"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.parquet)'" -l row-group-size-bytes -d "COPY [parquet] Target size of each row group in bytes"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.parquet)'" -l row-group-size -d "COPY [parquet] Target number of rows per row group"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.parquet)'" -l row-groups-per-file -d "COPY [parquet] Create new file after N row groups"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to=.*?(\\.json|\\.jsonl|\\.ndjson)'" -l array -d "COPY [json] Write JSON array of records (true) or newline-delimited (false)"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l format -a "auto newline_delimited array parquet csv tsv json jsonl arrow" -d "COPY [all] Explicit format: parquet, csv, json, arrow, jsonl"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l use-tmp-file -d "COPY [all] Write to temp file first to prevent broken overwrites"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l overwrite-or-ignore -d "COPY [all] Allow overwriting files (with partition_by)"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l overwrite -d "COPY [all] Remove existing files in targeted directories"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l append -d "COPY [all] Regenerate path if file exists (with partition_by)"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l filename-pattern -d "COPY [all] Pattern for filename, can use {uuid} or {id}"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l file-extension -d "COPY [all] File extension for generated files"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l per-thread-output -d "COPY [all] Generate one file per thread"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l file-size-bytes -d "COPY [all] Max file size before creating new file (e"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l partition-by -d "COPY [all] Columns to partition by using Hive scheme"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l return-files -d "COPY [all] Include created filepaths in query result"
complete -c reader -f -n "commandline -opc | string match -rq -- '--to|--format'" -l write-partition-columns -d "COPY [all] Write partition columns into files"
complete -c reader -F -l to -d "Export result to a file (CSV, JSON, Parquet)" -r
complete -c reader -f -l format -d "Output format (csv, tsv, json, jsonl, parquet) to stdout" -r -a "csv tsv json jsonl parquet"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l select -d "Select specific columns" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l where -d "Filter rows with a WHERE clause" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l join -s j -d "Join with another table (cumulative)" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l distinct -s d -d "Select distinct rows based on a column" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l sample -d "Sample N rows from the result" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l sort -s s -d "Sort result by columns (ORDER BY)" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l group-by -s g -d "Group result by columns (GROUP BY)" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l summarize -d "Show summary statistics of the result"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l sample-size -d "Number of lines to scan for auto-detection" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l limit -s l -d "Limit the number of rows returned" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l union-by-name -d "Whether to union files by name"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l ignore-errors -d "Whether to ignore errors"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l help -d "Show help message"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -s h -d "Show help message"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l mode -s m -a "box line json csv markdown" -d "Output format"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l paging -s p -d "Enable pagination using less"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l tui -s t -d "Open result in tablens TUI"
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l with -d "Add a CTE (Common Table Expression)" -r
complete -c reader -f -n "not commandline -opc | string match -rq -- '--to|--format'" -l no-truncate -d "Do not truncate output to terminal width"
complete -c reader -F
