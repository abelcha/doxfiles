complete -c lms -n '__fish_seen_subcommand_from ls' -l log-level -d '<value> - The level of logging to use. If not provided, the default level is "info". [optional]'
complete -c lms -n '__fish_seen_subcommand_from ls' -l host -d '<str>        - If you wish to connect to a remote LM Studio instance, specify the host here. Note that, in this case, lms will connect using client identifier "lms-cli-remote-<random chars>", which will not be a privileged client, and will restrict usage of functionalities such as "lms push". [optional]'
complete -c lms -n '__fish_seen_subcommand_from ls' -l port -d '<number>     - The port where LM'
complete -c lms -n '__fish_seen_subcommand_from ps' -l log-level -d '<value> - The level of logging to use. If not provided, the default level is "info". [optional]'
complete -c lms -n '__fish_seen_subcommand_from ps' -l host -d '<str>        - If you wish to connect to a remote LM Studio instance, specify the host here. Note that, in this case, lms will connect using client identifier "lms-cli-remote-<random chars>", which will not be a privileged client, and will restrict usage of functionalities such as "lms push". [optional]'
complete -c lms -n '__fish_seen_subcommand_from ps' -l port -d '<number>     - The port where LM Stud'
complete -c lms -n '__fish_seen_subcommand_from get' -l mlx -d '- Whether to include MLX models in the search results. If any of "--mlx" or "--gguf" flag i'
complete -c lms -n '__fish_seen_subcommand_from load' -l gpu -d '<0-1|off|max>       - How much to offload to the GPU. If "off", GPU offloading is disabled. If "max", all layers are offloaded to GPU. If a number between 0 and 1, that fraction of layers will be offl'
complete -c lms -n '__fish_seen_subcommand_from unload' -l log-level -d '<value> - The level of logging to use. If not provided, the default level is "info". [optional]'
complete -c lms -n '__fish_seen_subcommand_from unload' -l host -d '<str>        - If you wish to connect to a remote LM Studio instance, specify the host here. Note that, in this case, lms will connect using client identifier "lms-cli-remote-<random chars>", which will not be a privileged client, and will restrict usage of functionalities such as "lms push". [optional]'
complete -c lms -n '__fish_seen_subcommand_from unload' -l port -d '<number>     - The port where LM Studio c'
complete -c lms -n '__fish_seen_subcommand_from create' -l log-level -d '<value> - The level of logging to use. If not provided, the default level is "info". [optional]'
complete -c lms -n '__fish_seen_subcommand_from create' -l verbose -d '- Enable verbose logging.'
complete -c lms -n '__fish_seen_subcommand_from create' -l quiet -d '- Suppress all logging.'
complete -c lms -n '__fish_seen_subcommand_from create' -s h -l help -d '- show help'
complete -c lms -n '__fish_seen_subcommand_from import' -s y -l yes -d '- Suppress all confirmations and warnings. Will also attempt to automatically resolve the user and repository from the file name.'
complete -c lms -n '__fish_seen_subcommand_from import' -s c -l copy -d '- Copy the file instead of moving it. This is useful when you want to keep the original file in place.'
complete -c lms -n '__fish_seen_subcommand_from import' -s L -l hard-link -d '- Create a hard link instead of moving or copying the file. This is useful when you want to keep the or'

complete -f -c lms -n __fish_use_subcommand -a ls -d 'List all downloaded models'
complete -f -c lms -n __fish_use_subcommand -a ps -d 'List all loaded models'
complete -f -c lms -n __fish_use_subcommand -a get -d 'Searching and downloading a model from online.'
complete -f -c lms -n __fish_use_subcommand -a load -d 'Load a model'
complete -f -c lms -n __fish_use_subcommand -a unload -d 'Unload a model'
complete -f -c lms -n __fish_use_subcommand -a create -d 'Create a new project with scaffolding'
complete -f -c lms -n __fish_use_subcommand -a log -d 'Log operations. Currently only supports streaming logs from LM Studio via `lms log stream`'
complete -f -c lms -n __fish_use_subcommand -a import -d 'Import a model file into LM Studio'
